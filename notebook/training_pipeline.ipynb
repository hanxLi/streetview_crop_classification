{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorboard --quiet\n",
    "%pip install seaborn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# if using Apple MPS, fall back to CPU for unsupported ops\u001b[39;00m\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTORCH_ENABLE_MPS_FALLBACK\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/steeeve/Documents/csiss/streetview_crop_classification/cropClassification')\n",
    "sys.path.append('/Users/steeeve/Documents/csiss/streetview_crop_classification/cropClassification/model')\n",
    "import os\n",
    "# if using Apple MPS, fall back to CPU for unsupported ops\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from unet import originalUNet\n",
    "from compiler import ModelCompiler\n",
    "from dataloader import RoadsideCropImageDataset\n",
    "from loss import BalancedCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU with CUDA\n",
    "    print(\"Using CUDA\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Apple M1/M2 GPU with MPS (Metal Performance Shaders)\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fall back to CPU\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "        \"type\": \"originalUNet\",  # Example model type, replace with your actual model class name\n",
    "        \"params\": {\n",
    "            \"in_channels\": 9,  # Since we are using 9-channel input images\n",
    "            \"out_channels\": 3   # Number of output classes for segmentation\n",
    "        }\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"epochs\": 50,\n",
    "        \"batch_size\": 64,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"Adam\",\n",
    "            \"params\": {\n",
    "                \"lr\": 0.01\n",
    "            }\n",
    "        },\n",
    "        \"scheduler\": {\n",
    "            \"type\": \"StepLR\",\n",
    "            \"params\": {\n",
    "                \"step_size\": 10,\n",
    "                \"gamma\": 0.5\n",
    "            }\n",
    "        },\n",
    "        \"criterion\": BalancedCrossEntropyLoss(),  # or you can use your custom loss like BalancedCrossEntropyLoss\n",
    "        \"resume\" : False,\n",
    "        \"resume_epoch\" : None,\n",
    "    },\n",
    "    \"validation\": {\n",
    "        \"epochs\": 50,\n",
    "        \"batch_size\": 16\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"train_csv\": \"/workspace/data/data/masked_data_csiss/training/train_chipping_csv.csv\",  # Path to the training DataFrame (includes npy file paths)\n",
    "        \"val_csv\": \"/workspace/data/data/masked_data_csiss/validation/validation_chipping_csv.csv\", # Path to the validation DataFrame (includes npy file paths)\n",
    "        \"train_root_path\": \"/workspace/data/data/masked_data_csiss/training\",\n",
    "        \"val_root_path\": \"/workspace/data/data/masked_data_csiss/validation\",\n",
    "        \"image_column\": \"img_chip_path\",             # Column containing the image paths (npy files)\n",
    "        \"mask_column\": \"lbl_chip_path\",              # Column containing the mask paths\n",
    "        \"train_mean\": [93.8785585, 111.81092494, 76.94555781, 113.58929434, 206.93557473, 28.98472963,\n",
    "                       46.53684269, 113.74437327, 116.23856585],  # Mean values for training set normalization\n",
    "        \"train_std\": [53.24595916, 46.34658429, 45.91157286, 47.69937365, 82.32605363, 48.02506071,\n",
    "                       22.46416468, 52.31732116, 47.89290138],   # Std values for training set normalization\n",
    "        \"val_mean\": [88.62211239, 111.27628711, 75.19030815, 111.99622799, 223.21125121, 25.98495476, \n",
    "                     49.64829283, 115.91463906, 114.01573621],    # Mean values for validation set normalization\n",
    "        \"val_std\": [53.97481266, 46.47043658, 45.64034871, 48.20284577, 59.89659002, 41.7467965,\n",
    "                     20.82148233, 54.41768437, 47.68361442],     # Std values for validation set normalization\n",
    "    },\n",
    "    \"evaluation\": {\n",
    "        \"filename\": \"csiss_street_view_crop_classification.csv\",  # Evaluation metrics to be used\n",
    "        \"class_mapping\": {\n",
    "            0: \"Background\",\n",
    "            1: \"Maize\",\n",
    "            2: \"Soybean\"\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(config['dataset']['train_csv'])\n",
    "val_df = pd.read_csv(config['dataset']['val_csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RoadsideCropImageDataset(\n",
    "    dataframe=train_df,\n",
    "    root_dir=config['dataset']['train_root_path'],  # Root directory where images are stored\n",
    "    usage='train',  # Indicates training dataset\n",
    "    mean=config['dataset']['train_mean'],\n",
    "    std=config['dataset']['train_std']\n",
    ")\n",
    "\n",
    "val_dataset = RoadsideCropImageDataset(\n",
    "    dataframe=val_df,\n",
    "    root_dir=config['dataset']['val_root_path'],  # Root directory where images are stored\n",
    "    usage='val',  # Indicates validation dataset\n",
    "    mean=config['dataset']['val_mean'],\n",
    "    std=config['dataset']['val_std']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config['training']['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['training']['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = originalUNet(n_channels=config['model']['params']['in_channels'],\n",
    "                     n_classes=config['model']['params']['out_channels'])\n",
    "model_comp = ModelCompiler(model=model,\n",
    "                           params_init=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp.fit(\n",
    "    trainDataset=train_loader,\n",
    "    valDataset=val_loader,\n",
    "    epochs=config['training']['epochs'],\n",
    "    optimizer_name=config['training']['optimizer']['type'],\n",
    "    lr_init=config['training']['learning_rate'],\n",
    "    lr_policy='steplr',  # Use 'steplr' as specified in config\n",
    "    criterion=config['training']['criterion'],\n",
    "    log=True,  # Enable logging for TensorBoard\n",
    "    **config['training']['scheduler']['params'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
